19:52:04 From  Victor Chavarria gl  to  Everyone:
	Good Morning!
19:52:52 From  Vera Pfeiffer gl  to  Hosts and panelists:
	Good morning üôÇ
19:53:47 From  Vera Pfeiffer gl  to  Everyone:
	Good morning üôÇ
19:54:45 From  Mohammad Ayub gl  to  Hosts and panelists:
	Good morning
19:55:05 From  Jacqueline gl  to  Everyone:
	Good morning everyone!
19:55:18 From  Chris Kaiser gl  to  Everyone:
	morning
19:55:31 From  Andy Mak gl  to  Everyone:
	Good morning everyone
19:55:34 From  Sergio Bracho Argotte gl  to  Everyone:
	Good morning everyone!
19:55:39 From  Will McGuire gl  to  Everyone:
	haloooo
19:56:23 From  Juan Bermudez gl  to  Everyone:
	Good morning
19:56:40 From  Leng Khye Sut gl  to  Everyone:
	Good morning everyone
19:57:06 From  neil mody gl  to  Everyone:
	Good morning all
19:57:21 From  Faculty (Olympus)  to  Hosts and panelists:
	good morning/day everyone!
19:57:27 From  Chen Wei Ku gl  to  Everyone:
	Good morning
19:57:29 From  Pallavi Kawale gl  to  Everyone:
	Good morning everyone
19:58:27 From  Diallo Bocar Elimane gl  to  Everyone:
	Hello everyone
19:58:30 From  Lucy Edosomwan gl  to  Hosts and panelists:
	Good morning Vishnu, Professor and colleagues from Atlanta
19:58:37 From  Kevin Humbles gl  to  Everyone:
	Good morning
19:58:39 From  Katherine Morgan gl  to  Hosts and panelists:
	Good morning!
19:59:15 From  [GL] Vishnu Subramanian  to  Everyone:
	Hello everyone :)
19:59:51 From  Mariela Trigueros gl  to  Everyone:
	hello Everyone!
19:59:57 From  William Corwin gl  to  Everyone:
	Hey all :)
20:00:33 From  Mukul Mondal gl  to  Everyone:
	good morning to all
20:00:53 From  Fedor Galstyan gl  to  Everyone:
	Good morning!
20:00:57 From  Stephanie Hurtado Lonard gl  to  Everyone:
	how do i disable the full transcript?
20:01:01 From  Aditya Bandimatt gl  to  Everyone:
	Aloha from Bangalore!
20:01:06 From  Reena Choudhary gl  to  Everyone:
	good morning everyone
20:01:13 From  Prerna Mathur gl  to  Everyone:
	morning
20:01:22 From  Kurt Borg gl  to  Everyone:
	good morning from Los Angeles
20:02:21 From  Shan Siddiqui gl  to  Everyone:
	Good morning
20:02:26 From  frantz verella gl  to  Hosts and panelists:
	Good morning everyone
20:03:02 From  Yanhui  Wang gl  to  Everyone:
	Good morning
20:05:01 From  [GL - PO] Rama  to  Everyone:
	@Stephanie Hey, you can hide the transcript but you won't be able to disable it. You can find the option as you click on the 'Live Transcript' button beside the 'Raise Hand' button.
20:06:13 From  Rodrigo Senra gl  to  Everyone:
	You can "Hide subtile" in the Live Stranscript button (left click)
20:09:00 From  Chris Lieberman gl  to  Hosts and panelists:
	Shape of the cup
20:09:01 From  Mohammad Nazif Faqiry gl  to  Everyone:
	white, circle
20:09:05 From  Lucy Edosomwan gl  to  Everyone:
	tea/coffee cup
20:09:08 From  Jorge A. Marty Jr. gl  to  Everyone:
	the shape
20:09:09 From  Suresh Prathipati gl  to  Everyone:
	size
20:09:09 From  Chao Sun gl  to  Everyone:
	the shape
20:09:10 From  Lucy Edosomwan gl  to  Everyone:
	handle
20:09:10 From  Wai Julia Cheung gl  to  Everyone:
	it has a shape
20:09:10 From  Paula Iglesias Ot√°rola gl  to  Everyone:
	bounders
20:09:11 From  Mohamed Shibl gl  to  Everyone:
	it has a handle
20:09:11 From  Christopher Mahoney gl  to  Everyone:
	mug handle
20:09:13 From  Katherine Morgan gl  to  Hosts and panelists:
	It has a handle
20:09:14 From  Rajagopalan Kasthurirangan gl  to  Hosts and panelists:
	handle
20:09:15 From  Lex Gidley gl  to  Everyone:
	has edges
20:09:15 From  Chris Lieberman gl  to  Hosts and panelists:
	Boundaries that define a cup
20:09:17 From  Suresh Prathipati gl  to  Everyone:
	color
20:09:17 From  Victor Chavarria gl  to  Everyone:
	liquid inside
20:09:17 From  Sunitha Kona Naga gl  to  Everyone:
	curved edges
20:09:19 From  Lucy Edosomwan gl  to  Everyone:
	non glass
20:09:22 From  Prerna Mathur gl  to  Everyone:
	Shape
20:09:22 From  Sonia Thakur gl  to  Everyone:
	has a handle
20:09:25 From  Nirupana S Natarajan gl  to  Hosts and panelists:
	Color and shape
20:09:25 From  Anita Albert gl  to  Hosts and panelists:
	They have edges
20:09:26 From  Sergio Bracho Argotte gl  to  Everyone:
	coffee
20:09:27 From  Andy Mak gl  to  Everyone:
	Has a curve handle
20:09:30 From  Suresh Prathipati gl  to  Everyone:
	How many people are holding
20:09:33 From  Tony Thompson gl  to  Hosts and panelists:
	Close to hands, or face
20:09:34 From  Ravi Kumar gl  to  Everyone:
	colour shades
20:09:36 From  Mohammad Nazif Faqiry gl  to  Everyone:
	close to hand
20:09:42 From  Christopher Mahoney gl  to  Everyone:
	dark liquid inside
20:09:45 From  Anita Albert gl  to  Hosts and panelists:
	they exist in the world as objects to identify
20:09:51 From  Viktoriya Olari gl  to  Hosts and panelists:
	People often hold it in their arms
20:10:08 From  Arnold Estrada gl  to  Hosts and panelists:
	fingers
20:10:09 From  Victor Chavarria gl  to  Everyone:
	plate often present
20:10:09 From  Maurice Edwards gl  to  Everyone:
	one common feature is they're round, and about as tall as they are wide.
20:10:19 From  John Rogers gl  to  Everyone:
	Frequently an ellipse is visible
20:10:38 From  Wilberto W Montoya gl  to  Everyone:
	near human hands
20:10:45 From  Dev Soor gl  to  Everyone:
	There is a cup in hands in every image
20:10:46 From  Lex Gidley gl  to  Everyone:
	change in color
20:10:46 From  Paula Iglesias Ot√°rola gl  to  Everyone:
	position of the pixel matter
20:10:51 From  Maurice Edwards gl  to  Everyone:
	Objects aren't strung out in columns
20:10:51 From  Sergio Bracho Argotte gl  to  Everyone:
	Perspective
20:11:25 From  Chris Kaiser gl  to  Everyone:
	how well could this identify abnormalities on an image? for instance a how many mugs have a stain on them?
20:11:26 From  Thanh Dang gl  to  Hosts and panelists:
	can be multiple cups in an image
20:11:34 From  Mukul Mondal gl  to  Everyone:
	object direction
20:11:41 From  Maristela Monteiro gl  to  Everyone:
	only 2 don't have a person holding the cup
20:11:49 From  Rahul Chugh gl  to  Everyone:
	partial object
20:11:52 From  Sergio Bracho Argotte gl  to  Everyone:
	If it has patterns or different colors
20:12:17 From  Mohammad Nazif Faqiry gl  to  Everyone:
	no, pixel concentration will be there for cup
20:13:59 From  Chris Kaiser gl  to  Everyone:
	how many images would be a benchmark for training? or is it until optimal like our other models
20:16:20 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Chris
	Q:how well could this identify abnormalities on an image? for instance a how many mugs have a stain on them?
	A: For that you have to create a dataset which would have clean mugs and stained mugs. and they should be labelled appropriately
20:18:02 From  Chris Kaiser gl  to  Everyone:
	could that be utilized to find something new? discoloration, imperfections, without having pre trained it to look for specifics simply by saying this isn't like the others?
20:19:34 From  Al Ganeshkumar gl  to  Everyone:
	How does it handle it if the box only covers partial handle?
20:19:47 From  Shan Siddiqui gl  to  Everyone:
	Does the image format of the mug make a difference? For example, RAW images have much more data in them than simple JPEG images?
20:20:05 From  Suresh Prathipati gl  to  Everyone:
	How do we know the number for handle/jar etc?
20:20:12 From  Prerna Mathur gl  to  Everyone:
	How does it handle multiple images
20:20:27 From  Eduardo Brandao de Souza Mendes gl  to  Everyone:
	what if our cup is huge in the image and no detector alone can detect the 'big picture'?
20:21:21 From  Rajagopalan Kasthurirangan gl  to  Everyone:
	How would it handle if one mug is front of another? Like the image of the cheetah that was in one of the previous slides. It had detected 3 cheetah.
20:22:25 From  Dayna Levy gl  to  Everyone:
	it actually looks like it would also detect a mask as a mug
20:23:20 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Shan
	Q:Does the image format of the mug make a difference? For example, RAW images have much more data in them than simple JPEG images?
	A:That's a very good question. yes it can be the case that an image present on the surface of the mug might also be a viable object of interest in prediction
20:23:27 From  Lucy Edosomwan gl  to  Everyone:
	what is the least amount and max amount of filters on average that we see to achieve image recognition?
20:24:15 From  Al Ganeshkumar gl  to  Everyone:
	what is relu
20:24:17 From  Wilberto W Montoya gl  to  Everyone:
	Ok that was the reason professor mentioned to drop last layer, those are the ones that do classification...
20:24:27 From  Sergio Bracho Argotte gl  to  Everyone:
	Does CNN always use RELU activation?
20:24:31 From  Victor Chavarria gl  to  Everyone:
	this looks like layers of photoshop, very cool
20:24:34 From  Wilberto W Montoya gl  to  Everyone:
	on Monday I mean
20:25:31 From  Suresh Prathipati gl  to  Everyone:
	How do we detect? How do I know the number belongs to handle etc?
20:25:35 From  Brandi Bax gl  to  Everyone:
	The layers slide is *chef's kiss*
20:25:56 From  Mike Hankinson gl  to  Everyone:
	@Al. RELU is one type of activation function....see slides from Monday.
20:26:06 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Eduardo,
	Q:what if our cup is huge in the image and no detector alone can detect the 'big picture'?
	A: If it's big enough, it will still be handled by detectors because of functions like Maxpooling, average pooling that you'll learn along the course of this lecture. They usually break down an image from higher size to lower, capturing only important features
20:26:09 From  Thanh Dang gl  to  Hosts and panelists:
	what about the sizes of sliding windows and pictures? Do you set pictures to same size or do you set the sliding window relative to the image?
20:26:48 From  Steven Rubio gl  to  Everyone:
	Can we quantify a 3D shape of a cup and apply the common denominator (in shapes) to the images we're trying to observe?
20:26:54 From  [GL-TA] Avijit  to  Everyone:
	@Lucy Q:what is the least amount and max amount of filters on average that we see to achieve image recognition?		A:There is no correct answer as to what the best number of filters is. This strongly depends on the type and complexity of your (image) data. A suitable number of features is learned from experience after working with similar types of datasets repeatedly over time. In general, the more features you want to capture (and are potentially available) in an image the higher the number of filters required in a CNN.
20:27:42 From  Wilberto W Montoya gl  to  Everyone:
	These filters are NOT provided to the NN but is actually the NN that finds the filters by training, isn't it?
20:27:54 From  Mukul Mondal gl  to  Everyone:
	Here we are capturing data from all the area, so how do we know, which all part to combine?
20:28:03 From  Hongbin Liu gl  to  Everyone:
	Dot product is some projection + scaling. What would be intuition behind dot product help to manifest ‚Äúfeatures‚Äù
20:28:07 From  Wilberto W Montoya gl  to  Everyone:
	can we check the filters found after training?
20:28:19 From  [GL] Vishnu Subramanian  to  Everyone:
	@Wilberto The size of the filters is a hyperparameter, but the values in those filters are learned by the neural network.
20:28:37 From  Lucy Edosomwan gl  to  Everyone:
	Avijit- Thank you
20:28:39 From  Jian Yang gl  to  Everyone:
	What information is left after a filtering?  an array or a number?
20:28:54 From  Kalpana Singh gl  to  Everyone:
	what is I put handle on one side of cup but in some picture It is on other side
20:29:00 From  Chris Lieberman gl  to  Everyone:
	Found this on Machine Learning blog:
20:29:04 From  Chris Lieberman gl  to  Everyone:
	What is the difference between pooling and convolution?
	Convolutional layers in a convolutional neural network summarize the presence of features in an input image. ... Pooling layers provide an approach to down sampling feature maps by summarizing the presence of features in patches of the feature map.
20:30:04 From  Hongbin Liu gl  to  Everyone:
	Are filters initialized with random numbers?
20:30:11 From  Mohammad Nazif Faqiry gl  to  Everyone:
	How do you decide the size of the patch and what numbers in the patch?
20:30:37 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Sergio
	Q:Does CNN always use RELU activation?
	A: No, CNNs use a variety of activation functions along side ReLu ofcourse. The simple reason being no pixels can have negative value
20:30:56 From  Lucy Edosomwan gl  to  Everyone:
	Do  the patches overlap i.e. the blue and red squares, or does it take each pixel 1 by 1?
20:31:36 From  Wilberto W Montoya gl  to  Everyone:
	Ithink each pixel is a vector with the 3 colors
20:31:50 From  Sergio Bracho Argotte gl  to  Everyone:
	This reminds me the kids movie "The Mitchells vs the machines", were the robots collapse trying to identify if its a pug, a pig or bread
20:32:30 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Mohammad,
	Q:How do you decide the size of the patch and what numbers in the patch?
	A:If you're referring to filters, we decide the size of it by a little domain knowledge. usually we pick the common sizes. However the numbers , those are learnt over time by the process of training
20:33:12 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Wilberto, yes. 
	also alternately , each colour channel is a 2-D vector
20:34:18 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Hongbin
	Q:Are filters initialized with random numbers?
	A: Yes, great thinking. They are random numbers first and later they learn through the training process
20:34:31 From  [GL-TA] Avijit  to  Everyone:
	@Hongbin Q:Are filters initialized with random numbers?	A:Typically, filter values in CNN are initialized randomly in a normal distribution or other distributions. Later on, a machine fine tunes these values during training.
20:35:04 From  John Rogers gl  to  Everyone:
	010
20:35:10 From  Sergio Bracho Argotte gl  to  Everyone:
	0 1 0
20:36:17 From  Chris Lieberman gl  to  Everyone:
	Couldn‚Äôt the ‚Äúafter convolution‚Äù value be 3 if the inputs & weights are both 1?
20:36:58 From  Wilberto W Montoya gl  to  Everyone:
	Pixel colour are only positive values
20:36:59 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Jian,
	Q:What information is left after a filtering?  an array or a number?
	A:At the start of the training, the filters are unable to extract any information. But with time, some filters get modified to identify horizontal edges, some vertical edges, some darker areas, some lighter areas. so a series of filters are responsible for identifying features like maybe an eyebrow, or maybe the handle of a mug.
20:37:06 From  Hongbin Liu gl  to  Everyone:
	If the size of filter is hyper parameter, what does the big or the small size mean? Big -> more blur  less distinct ?
20:38:41 From  Victor Chavarria gl  to  Everyone:
	if we have 100 parameters, do we still have a single digit after convolution?
20:39:11 From  Victor Chavarria gl  to  Everyone:
	w‚Äôs are the parameters, correct?
20:40:00 From  Mike Hankinson gl  to  Everyone:
	Site has this example with moving gifs showing the convolutions with stride length, padding and pooling.....(this is a tough topic)   https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53
20:40:21 From  Zach Barnett gl  to  Hosts and panelists:
	you‚Äôre not capturing end pixels
20:40:28 From  Sergio Bracho Argotte gl  to  Everyone:
	After passing through the filter
20:40:33 From  Victor Chavarria gl  to  Everyone:
	the edges go away
20:40:34 From  Brian A Sakarata gl  to  Everyone:
	Thanks  Mike!
20:40:35 From  Suresh Prathipati gl  to  Everyone:
	detector
20:40:36 From  Chao Sun gl  to  Everyone:
	depend on the size of the filter
20:40:37 From  Mukul Mondal gl  to  Everyone:
	because of Filter
20:40:38 From  Deepak Gaikwad gl  to  Everyone:
	due to filter size
20:40:39 From  HARIISH UPPILI gl  to  Everyone:
	It ignore duplicates ?
20:40:41 From  Halyna Hendzelyuk gl  to  Hosts and panelists:
	Because of the filter
20:40:42 From  Thanh Dang gl  to  Everyone:
	you can‚Äôt slide all the way to the end
20:40:54 From  Lucy Edosomwan gl  to  Everyone:
	it almost acts as a reduction method
20:43:01 From  Wilberto W Montoya gl  to  Everyone:
	So the padding is half the size of you filter
20:43:59 From  Will McGuire gl  to  Everyone:
	is there a function for determining optimum stride?
20:44:03 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Victor,
	Q:if we have 100 parameters, do we still have a single digit after convolution?
	A:Yes for a full filter, there is a single result of the convolution
20:44:21 From  Victor Chavarria gl  to  Everyone:
	thanks
20:45:12 From  Lucy Edosomwan gl  to  Everyone:
	what is the significance in stride # in the final output? i.e. 2 v 3 v 4 strides?
20:46:47 From  Ravi Kumar gl  to  Everyone:
	How Filter size is selected? At the end of the filtering, last rows will always be zeroes and are there any chances of misinterpretation?
20:48:07 From  Steven Rubio gl  to  Everyone:
	Is it useful to apply an effect to the images to sharpen our visual on the edges and then run our logic by 4x4 pixels?
20:48:11 From  Sarah Yang gl  to  Everyone:
	Is there any trainings involved in creating Filters?
20:48:24 From  Sergio Bracho Argotte gl  to  Everyone:
	Can I change the size of the filter?
20:48:45 From  Lucy Edosomwan gl  to  Everyone:
	Thank you
20:52:21 From  Wilberto W Montoya gl  to  Everyone:
	So every time we apply a filter we "loss" some information, limiting the capacity of the NN to learn from the missed data
20:52:28 From  Victor Chavarria gl  to  Everyone:
	it seems like instagram is using us as training data for Meta‚Äôs neuro network. and we are all happy aplying filters to our pictures‚Ä¶ not a question, just an observation
20:54:06 From  [GL] Vishnu Subramanian  to  Everyone:
	@Wilberto Yes, that's why the role of convolutions and pooling is important - they try to retain only the information from the image we really need, and forget the rest of the information. For example, to detect a duck in an image, the color of the sky above the lake is not really important.
20:54:49 From  Wilberto W Montoya gl  to  Everyone:
	thanks Vishnu
20:56:36 From  Fernando Garcia Corona gl  to  Everyone:
	in this example we could have done a filter that contains the square directly no?
20:57:37 From  Wilberto W Montoya gl  to  Everyone:
	@fernando, yes but it will tied to the 3X3 square size the edge approach is valid for any size square
20:59:22 From  Chris Kaiser gl  to  Everyone:
	how would that work without the white space in the middle of this one?
20:59:58 From  Erika Spangler gl  to  Hosts and panelists:
	Quick nomenclature question: Does layer 1 have 2 channels? What is a channel?
21:00:38 From  Erika Spangler gl  to  Everyone:
	Quick nomenclature question: what is a channel? Does layer 1 have 2 channels?
21:00:43 From  Fernando Garcia Corona gl  to  Everyone:
	thanks @wilberto and @professor
21:01:00 From  Deepak Gaikwad gl  to  Everyone:
	Is the horizontal edge filter is detecting based on white horizontal squares or the black horizontal squares?
21:01:03 From  Thanh Dang gl  to  Everyone:
	does the CNN automatically learn the final ‚Äúshapes‚Äù through labels in the training data?
21:01:14 From  [GL] Vishnu Subramanian  to  Everyone:
	@Deepak Black horizontal squares
21:01:32 From  NING LI gl  to  Everyone:
	Are all these learnt automatically and we are trying to interpret the process here, please?
21:02:31 From  NING LI gl  to  Everyone:
	Or how much is needed from the human design?
21:03:35 From  NING LI gl  to  Everyone:
	That is the question. How do you pass this ‚Äòhidden box‚Äô learnt strategy to others?
21:03:45 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Thanh
	Q:does the CNN automatically learn the final ‚Äúshapes‚Äù through labels in the training data?
	A:The shapes of Convolutional filters are given by the programmer only, but the weights are modified during training
21:06:04 From  [GL] Vishnu Subramanian  to  Everyone:
	@Ning Yes, in the next lecture, we will cover the idea of "Transfer Learning" where the initial learnt weights from one model trained on one task can be used for another similar task as well, because the initial logic around detecting edges and simple shapes and patterns is common to many image classification tasks
21:06:37 From  NING LI gl  to  Everyone:
	Is there addition learning if it is not horizontal or vertical? Say it is 30 degree tilted cup? Or it is the same?
21:07:39 From  Omar Fahmy gl  to  Everyone:
	Are there other pooling functions? This is ma
21:07:50 From  [GL] Vishnu Subramanian  to  Everyone:
	@Ning So far, the convolution operation and filtering has not been "rotationally invariant", and that can be a problem for such neural networks. The process to make such models more robust to rotation is coming later in this session :)
21:08:22 From  NING LI gl  to  Everyone:
	thx
21:08:38 From  [GL] Vishnu Subramanian  to  Everyone:
	@Omar Yes - there are a few schemes for pooling. Max/min pooling and average pooling are two common ones.
21:08:44 From  NING LI gl  to  Everyone:
	Can you ‚Äòspin‚Äô the imagine first before processing?
21:08:53 From  Omar Fahmy gl  to  Everyone:
	Thanks Vishnu
21:12:16 From  NING LI gl  to  Everyone:
	So you can come into the ‚Äòhidden box‚Äô to engineer the network, please?
21:12:41 From  Deepak Gaikwad gl  to  Everyone:
	what were the scores on the top of the bars on Deep CNN slide?
21:13:20 From  [GL] Vishnu Subramanian  to  Everyone:
	@Deepak The misclassification rate, or the errors. The errors of the best models on ImageNet have been decreasing (or the models have been getting better accuracies) the deeper the network.
21:14:54 From  Lex Gidley gl  to  Everyone:
	Sorry, I missed this, what "connections" does ResNet skip?
21:17:58 From  [GL] Vishnu Subramanian  to  Everyone:
	@Lex Essentially the 'x' (input) skips a layer and goes straight to the second layer to contribute to its computing, in addition to going through the first layer. So the input for the second layer is not just F(x), but F(x) + x.
21:18:39 From  Lex Gidley gl  to  Everyone:
	Vishnu - thank you
21:19:52 From  NING LI gl  to  Everyone:
	Are there databases of well developed detectors that people can plug in and use?
21:21:04 From  Brian A Sakarata gl  to  Everyone:
	there's aws rekognition
21:21:20 From  Brian A Sakarata gl  to  Everyone:
	@NING LI https://aws.amazon.com/rekognition/
21:21:35 From  NING LI gl  to  Everyone:
	thx
21:22:01 From  Brian A Sakarata gl  to  Everyone:
	and then for data you can get it from aws marketplace or Kaggle or other places
21:22:12 From  Zach Barnett gl  to  Hosts and panelists:
	almost like a computational Lag?
21:22:14 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Ning,
	Q:Are there databases of well developed detectors that people can plug in and use?
	A: It is an interesting concept. we will try to find something along these lines
21:22:55 From  NING LI gl  to  Everyone:
	üòÄ
21:23:02 From  NING LI gl  to  Everyone:
	thx
21:23:53 From  Lex Gidley gl  to  Everyone:
	cool. Thanks
21:25:21 From  Jian Yang gl  to  Everyone:
	When are the edge detectors  required be the conv1 layer?
21:25:41 From  Keith Mullen gl  to  Everyone:
	per my question, that makes sense...thanks!! :)
21:29:58 From  Chris Lieberman gl  to  Everyone:
	Performance would drop
21:30:09 From  Chris Lieberman gl  to  Everyone:
	Or take longer to train
21:30:13 From  Suresh Prathipati gl  to  Everyone:
	same
21:30:14 From  Sunil Acharya gl  to  Everyone:
	you need rotational invariance
21:30:18 From  Thanh Dang gl  to  Everyone:
	would be similar
21:30:20 From  Victor Chavarria gl  to  Everyone:
	good,
21:30:20 From  Prerna Mathur gl  to  Everyone:
	same
21:30:20 From  Omar Fahmy gl  to  Everyone:
	Depends on the training data
21:30:20 From  Mukul Mondal gl  to  Everyone:
	same
21:30:28 From  Maurice Edwards gl  to  Everyone:
	I think the rotation matters - the representation wouldn't match
21:30:30 From  Thanh Dang gl  to  Everyone:
	would be similar bc of the pooling
21:30:32 From  Reto Voegeli gl  to  Everyone:
	same
21:30:35 From  Fernando Garcia Corona gl  to  Everyone:
	very good detection I would guess
21:30:41 From  Steven Rubio gl  to  Everyone:
	the matrix will have to rotate too, so the performance will drop.
21:30:50 From  Victor Chavarria gl  to  Everyone:
	eigen vector and value use?
21:31:57 From  Raji Kandan gl  to  Everyone:
	strides for filters? horizontal/vertical movement may not be enough??
21:32:18 From  Chris Kaiser gl  to  Everyone:
	why does it struggle so much with the dog? detail?
21:32:39 From  Rodrigo Senra gl  to  Everyone:
	self-symmetry
21:32:40 From  Chris Lieberman gl  to  Everyone:
	Is this graph during the training process or afterwards (after the model has been trained?
21:32:42 From  Maurice Edwards gl  to  Everyone:
	heh -  I struggled with the dog!
21:32:58 From  Sunil Acharya gl  to  Everyone:
	Maurice your NN needs rotational invariance
21:33:14 From  Steven Rubio gl  to  Everyone:
	haha
21:33:21 From  [GL] Vishnu Subramanian  to  Everyone:
	@Chris This is after the training, it's already been trained, and we're testing it on rotated images
21:33:23 From  Sunil Acharya gl  to  Everyone:
	QR decomposition
21:33:32 From  NING LI gl  to  Everyone:
	Can this be a strategy for learning? Spinning and learning.
21:34:39 From  Maurice Edwards gl  to  Everyone:
	Apologies, work called. Must go - I'll catch the recording
21:34:49 From  John Rogers gl  to  Everyone:
	Face ID needs to implement this!
21:34:51 From  [GL] Vishnu Subramanian  to  Everyone:
	@Ning Yes - this is a part of "Data Augmentation"
21:34:59 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	@Ning 
	Q:Can this be a strategy for learning? Spinning and learning.
	A:It is included in data augmentation and training practises
21:35:12 From  NING LI gl  to  Everyone:
	thx
21:36:36 From  Victor Chavarria gl  to  Everyone:
	documented on netflix show
21:38:06 From  Lucy Edosomwan gl  to  Everyone:
	very interesting
21:38:22 From  Prerna Mathur gl  to  Everyone:
	We are facing this problem now
21:38:25 From  Will McGuire gl  to  Everyone:
	Wouldn't that be a factor of where the majority of the training data came from? Bias, yes
21:38:48 From  Lucy Edosomwan gl  to  Everyone:
	bias training bias, training teaching bias
21:41:16 From  Kevin Gonzalez gl  to  Everyone:
	The sky
21:41:23 From  Fernando Garcia Corona gl  to  Everyone:
	sky
21:41:23 From  Sergio Bracho Argotte gl  to  Everyone:
	4 wheels?
21:41:32 From  Omar Fahmy gl  to  Everyone:
	Headlights/tailights
21:41:39 From  Omar Fahmy gl  to  Everyone:
	Side mirrors
21:41:39 From  Martin Niehoff gl  to  Everyone:
	large Areas with same Color + wheels = car
21:41:41 From  Pornthip Suyasith gl  to  Hosts and panelists:
	Car light
21:41:44 From  Chris Kaiser gl  to  Everyone:
	mirrors
21:41:49 From  Santiago Lovato gl  to  Everyone:
	car looks like a box
21:41:52 From  Zuhair Nara gl  to  Everyone:
	straight lines
21:41:52 From  Wilberto W Montoya gl  to  Everyone:
	shinny colors
21:42:06 From  Sergio Bracho Argotte gl  to  Everyone:
	ventilation for engine
21:42:18 From  Will McGuire gl  to  Everyone:
	size relation to surface, or is that too complicated?
21:42:31 From  Deepak Gaikwad gl  to  Everyone:
	license plate
21:42:35 From  Sergio Bracho Argotte gl  to  Everyone:
	windshield
21:42:38 From  Zuhair Nara gl  to  Everyone:
	shine
21:42:56 From  Victor Manuel Lara Villa gl  to  Hosts and panelists:
	windshield
21:42:58 From  Raji Kandan gl  to  Everyone:
	size
21:43:34 From  Paula Iglesias Ot√°rola gl  to  Everyone:
	We should use real cars: not that clean and new, and pictures with no so nice weather
21:43:37 From  Will McGuire gl  to  Everyone:
	or a boat
21:45:01 From  FABIANA P NOVELLO gl  to  Everyone:
	check for front/break lights?
21:45:14 From  Omar Fahmy gl  to  Everyone:
	How do you check that?
21:45:28 From  Fernando Garcia Corona gl  to  Everyone:
	it if it something red, you could confuse it wth the tongues
21:46:43 From  Tony Thompson gl  to  Hosts and panelists:
	Position in the night sky
21:46:44 From  Martin Niehoff gl  to  Everyone:
	poysition
21:46:44 From  Thanh Dang gl  to  Everyone:
	location
21:46:48 From  Kevin Humbles gl  to  Everyone:
	Positioning
21:46:48 From  Omar Fahmy gl  to  Everyone:
	White in the top right and bottom right is star
21:46:49 From  Paula Iglesias Ot√°rola gl  to  Everyone:
	position
21:46:49 From  Raji Kandan gl  to  Everyone:
	location?
21:46:50 From  Mukul Mondal gl  to  Everyone:
	shape
21:46:50 From  Fernando Garcia Corona gl  to  Everyone:
	how close it is to border
21:46:51 From  Aditya Bandimatt gl  to  Everyone:
	location
21:46:53 From  Diallo Bocar Elimane gl  to  Everyone:
	location
21:46:54 From  Srikanth Panchavati gl  to  Hosts and panelists:
	shape
21:47:09 From  Chris Lieberman gl  to  Everyone:
	Is the algorithm relying on collinearity to take these shortcuts?
21:47:47 From  Wilberto W Montoya gl  to  Everyone:
	Bad student NN, you do not learn üòâ
21:48:32 From  Sergio Bracho Argotte gl  to  Everyone:
	Shoulder pneumonia
21:48:34 From  Cheslan Simpson gl  to  Everyone:
	For more complex images, how do you know what features NN use to train on? Is this "explainability". Can you touch on that and explain it?
21:50:06 From  Will McGuire gl  to  Everyone:
	could an overlay like that be used to hide images from a search?
21:52:07 From  Will McGuire gl  to  Everyone:
	or conversely, a signature that isn't visible
21:52:36 From  Rodrigo Senra gl  to  Everyone:
	What tools do we use to debug NN?
21:52:54 From  Sunil Acharya gl  to  Everyone:
	Did we solve the Car-feature problem- I missed the thread of thought
21:53:41 From  Fernando Garcia Corona gl  to  Everyone:
	@Sunil by augmenting the data, cropping images for example, would force the model to learn something different
21:54:28 From  [GL] Vishnu Subramanian  to  Everyone:
	 @Sunil Yes, to prevent the neural network from wrongly associating cars with the presence of a sky, give it images of cars without a sky as well, for example.
21:54:29 From  Sunil Acharya gl  to  Everyone:
	@Fernando- but the size of the convolution filter already kind of does it..
21:55:28 From  Fernando Garcia Corona gl  to  Everyone:
	Is there a way to highlight what inside an image you would like to learn?
21:55:33 From  NING LI gl  to  Everyone:
	Is there a way to output how the network learnt after the training?
21:56:35 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	you can get the weights vector if that helps
21:56:55 From  Nikhil Kamma gl  to  Hosts and panelists:
	Vishnu, how is the data file prepared, in the project for digits we have an h5 file, but wondering in our real world, how do we do data preparation, prepare files like h5
21:57:02 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	in case where you can have intuitions based upon it
21:57:32 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	however other than that, you can plot out the training errors versus epochs. like how the errors reduced over time.
21:58:22 From  Fernando Garcia Corona gl  to  Everyone:
	thanks
21:58:56 From  Wilberto W Montoya gl  to  Everyone:
	Does object detection when we provide the coordinates could help to avoid taking wrong data?
21:58:58 From  NING LI gl  to  Everyone:
	For example is it the location or the shape?
21:59:07 From  NING LI gl  to  Everyone:
	Other than testing it, can we see it?
21:59:35 From  NING LI gl  to  Everyone:
	Thx
22:00:30 From  Sivakumar Visweswaran gl  to  Everyone:
	thank you
22:00:32 From  Kevin Humbles gl  to  Everyone:
	Ok, Thanks professor
22:00:32 From  Maristela Monteiro gl  to  Everyone:
	Thanks!!
22:00:33 From  Thanh Dang gl  to  Everyone:
	thank you!
22:00:38 From  Juan Montalvo Godina gl  to  Hosts and panelists:
	Thanks
22:00:43 From  Victor Chavarria gl  to  Everyone:
	thank you professor
22:00:45 From  Mike Hankinson gl  to  Everyone:
	This topic is amazing! Thanks, Stefanie.
22:00:50 From  Lex Gidley gl  to  Everyone:
	Thank you
22:00:51 From  Cristina Chiquinquir√° Hern√°ndez Labrador gl  to  Hosts and panelists:
	Thanks
22:00:52 From  Cheslan Simpson gl  to  Everyone:
	Thanks Prof!!
22:00:53 From  My Coyne gl  to  Hosts and panelists:
	Many (if not all) applications for CNN, FNN, and Deep Learning are for computer vision.  Indeed Vision and Image Processing advanced  so much.  I would like to ask what other applications that applies CNN or Neural Networks, in general.  Any examples on detecting the nuance in the language?  Or nuance on the people facial expression?
22:00:55 From  Jacqueline gl  to  Everyone:
	Thank you so much professor!
22:01:02 From  Mukul Mondal gl  to  Everyone:
	Thank you professor
22:01:22 From  Kuldeep Rawat gl  to  Everyone:
	Thank you
22:01:55 From  Rodrigo Senra gl  to  Everyone:
	Thank you all. Have to drop unfortunately
22:01:58 From  Shajan Thomas gl  to  Everyone:
	Thank you Professor!!
22:02:27 From  Sunil Acharya gl  to  Everyone:
	Can you comment on the Captcha problem if you have some time? (eg: Why are they so difficult if letter recognition is easy otherwise)
22:02:32 From  Mukul Mondal gl  to  Everyone:
	Can you apply CNN on time series data / dynamic data
22:03:34 From  Saradha Ravi gl  to  Hosts and panelists:
	Can they be used with bag of words model in text corpora?
22:03:45 From  Cheslan Simpson gl  to  Everyone:
	Jumping ahead here. What are the latest tools for image recognition? I hear about transformers. What are those?
22:04:01 From  LINGFEI LI (FIONN) gl  to  Everyone:
	Would CNN do good job on scanning and detecting cancer cells?
22:04:04 From  Sunil Acharya gl  to  Everyone:
	So CNN trained on photographic image won't appreciate cubism for a while.. what a pitty
22:04:36 From  Chao Sun gl  to  Everyone:
	Is ResNet only a enhanced model for CNN or it can also applied to uses case that's not image recognition etc?
22:08:13 From  [GL-TA] Debjyoti Ghosh  to  Everyone:
	Hi Chao, it usually caters to image recognition tasks only
22:12:03 From  Sunil Acharya gl  to  Everyone:
	Can you apply CNN to more of a "continuous variable" data?
22:12:51 From  Sunil Acharya gl  to  Everyone:
	Not necessarily regression
22:14:24 From  Sunil Acharya gl  to  Everyone:
	You have all these "gradients" and "differential" operators in the learning algorithm -I am puzzled how it works for discrete daa
22:14:25 From  Sunil Acharya gl  to  Everyone:
	data
22:14:42 From  Sunil Acharya gl  to  Everyone:
	maybe I need to work a simple example..
22:14:53 From  Lucy Edosomwan gl  to  Everyone:
	misremembering- now that is a great word
22:16:53 From  Hongbin Liu gl  to  Everyone:
	I am trying to get some math intuition behind filter. Dot product is projection and scaling; how projection and scaling can help with capture ‚Äúfeatures‚Äù or things like edges ?
22:18:45 From  Mukul Mondal gl  to  Everyone:
	Within neural network, how do you handle things like: Happy face, Sad Face, exciting face, speaking face. I mean, there could be unlimited number of combination of  an image
22:19:54 From  Sunil Acharya gl  to  Everyone:
	To move from image to video recognition, how does CNN fair in this field - say detecting a specific motion -is CNN has the speed to do this to be of practical use?
22:20:02 From  Sunil Acharya gl  to  Everyone:
	does CNN..
22:21:34 From  [GL] Vishnu Subramanian  to  Everyone:
	@Mukul There's an interesting dataset called fer2013 on Kaggle - neural networks have been applied to facial emotion detection on that dataset :)
22:23:06 From  Sunil Acharya gl  to  Everyone:
	@Mukul smiling/frowning can be classified as geometric transformations..
22:24:52 From  Wilberto W Montoya gl  to  Everyone:
	Can Object detection or Fully Convolutional Networks could help to make sure we are identifying the right object?
22:25:08 From  Ravi Kumar gl  to  Everyone:
	https://link.springer.com/article/10.1007/s11661-020-06008-4: highlights usage of CNN/ t-SNE for microstructural analysis of materials.
22:26:35 From  Sunil Acharya gl  to  Everyone:
	Hi Ravi Kumar why are you interested in this? There are similar applications in 3D printing (metals/ceramics) and also QAQC
22:28:42 From  Wilberto W Montoya gl  to  Everyone:
	Wow something like GAN but helping each other
22:29:59 From  Asmaa Soliman AbuMaziad gl  to  Everyone:
	Thank you all
22:30:01 From  Wilberto W Montoya gl  to  Everyone:
	Thank you So much!
22:30:07 From  Will McGuire gl  to  Everyone:
	thankssomuch
22:30:16 From  Brian A Sakarata gl  to  Everyone:
	This stuff is so fascinating, thank you so much
22:30:20 From  Michael Jeffries gl  to  Everyone:
	Thanks
22:30:44 From  venkata Ratna Priya moganti gl  to  Hosts and panelists:
	Any Good book you suggest on Deep Learning ?
22:30:56 From  Pallavi Kawale gl  to  Everyone:
	Thank u so much all of u ..its very helpful üòä
22:30:57 From  Alvin Kuo gl  to  Everyone:
	Thank you professor, Drew and Vishnu! üôÇ
22:31:03 From  Victor Chavarria gl  to  Everyone:
	Thank you,
22:31:05 From  Oktay Selcuk gl  to  Everyone:
	thank you
22:31:07 From  Ji Yoon Oh gl  to  Everyone:
	Thank you!
22:31:09 From  JoAnna Rhoden-Plaza gl  to  Everyone:
	Thank you
22:31:10 From  Blessy Joy Chamaparampil gl  to  Everyone:
	Thank you all.
22:31:10 From  MARIA SUSANA REZZONICO gl  to  Everyone:
	Thank you!
22:31:13 From  Lucy Edosomwan gl  to  Everyone:
	Thank You!!!
22:31:17 From  Leng Khye Sut gl  to  Everyone:
	Thank you!
22:31:18 From  Mukul Mondal gl  to  Everyone:
	thank you all
22:31:18 From  venkata Ratna Priya moganti gl  to  Hosts and panelists:
	Thank you
22:31:19 From  Yanhui  Wang gl  to  Everyone:
	Thank you.
22:31:23 From  Chao Sun gl  to  Everyone:
	thanks
